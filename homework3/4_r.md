**Made by Nicol√≤ Baroncini (1834907)**

## Research (4_R)
### Explain what are marginal, joint and conditional distributions and how we can explain the Bayes theorem using relative frequencies.
A ***joint distribution*** is done considering two or more statistical variables, in the case of two variables it is called bivariate distribution. \
The joint distribution for X, Y, ... is defined as how many statistical units of a population falls in any particular range or discrete set of values specified for that variables. \
In the next table, called contingency table, can be found an example where it's reported a bivariate distribution with relative frequencies instead of absolute values. For instance, in position (0,0), there's the relative frequency of statistical units that has X=Red and Y=Red.

![Schermata 2021-10-11 alle 09 16 00](https://user-images.githubusercontent.com/78324346/136748067-9e54d3d1-08dd-451d-b2d9-592350a21a8f.png)

To compute the joint relative frequency for any tuple of values that some statistical variable acquires, it's needed to count how many statistical units have those values for the variables and divide it for the number of statistical units of the population.

The ***marginal distribution*** can be obtained, in the example already showed, by summing the values of a row for the marginal distribution of X and the values of columns for the marginal distribution of Y. It's in called marginal distribution because it is usually represented in the margins of the table as shown below.

![Schermata 2021-10-11 alle 09 34 06](https://user-images.githubusercontent.com/78324346/136750378-cb05c757-d9b4-4418-b075-f1aa2ce724ca.png)

F(X) is the relative frequency associated to any values that a statistical unit can acquire of the variable X. F(Y) can be defined as the same but related to variable Y. \
This concept can be extended to a multidimensional joint distribution by fixing a value of the variable of which we want to compute the marginal distribution and sum the relative frequencies associated to it for any values of the other not fixed variables. 

The ***conditional distribution***, in a joint distribution of X and Y, is the number of statistical units that has a certain value of X known the value of Y and it is mathematically written as F(X=x|Y=x). \
For example, taking up the example already showed, we can compute the relative frequency of X=Red knowing Y=Blue: \
```
F(X=Red | Y=Blue) = 2/3 
```
It's so because we have 2 out of 9 that has Y=Blue and X = Red and 1 out of 9 that has Y = Blue and X = Red. So 3 units has Y=Blue, known this i want to know how many of them has X=Red and it's 2 out of 3. \
This concept can be extended to multivariate distributions.

Let's now talk about ***Bayes Theorem***, it says that:

![4](https://user-images.githubusercontent.com/78324346/136758460-2a27d5c8-58c5-4e43-94ed-177a3fa6e220.png)

This theorem can be explained using relative frequencies as below:

![Foglio di brutta-2](https://user-images.githubusercontent.com/78324346/136764231-d0f3cfa8-e196-4adc-ae99-8f1aa29b9cd6.jpg)

### Explain the concept of statistical independence and why, in case of independence, the relative joint frequencies are equal to the products of the corresponding marginal frequencies.

*References:* \
[1] [https://en.wikipedia.org/wiki/Joint_probability_distribution](https://en.wikipedia.org/wiki/Joint_probability_distribution) \
[2] [https://en.wikipedia.org/wiki/Marginal_distribution](https://en.wikipedia.org/wiki/Marginal_distribution) \
[3] [https://en.wikipedia.org/wiki/Conditional_probability_distribution](https://en.wikipedia.org/wiki/Conditional_probability_distribution) \
[4] [https://en.wikipedia.org/wiki/Bayes%27_theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem)

**Made by Nicolò Baroncini (1834907)**

## Research (10_R)
### Distributions of the order statistics: look on the web for the most simple (but still rigorous) and clear derivations of the distributions, explaining in your own words the methods used.

Before talking about the distributions of the order statistics let's see some notation.

Let X1, X2,..., Xn be a random sample of size n from some distribution. We denote the order statistics by

![image](https://user-images.githubusercontent.com/78324346/141741942-6d085076-eb2e-4cfa-b59b-e29853892c34.png)

In what follows, we will derive the distributions and joint distributions for each of these statistics
and groups of these statistics.

**The distribution of the minimum**\
Suppose that X1, X2,...,Xn is a random sample from a continuous distribution with pdf f and cdf F. We will now derive the pdf for X(1), the minimum value of the sample. The game plan will be to relate the cdf of the minimum to the behavior of the individual sampled values X1, X2,..., Xn for which we know the pdf and cdf.

The CDF for the minimum is

![Schermata 2021-11-15 alle 08 52 28](https://user-images.githubusercontent.com/78324346/141742868-2fa69b4a-63ef-49b7-8ba9-46d8c44c9166.png)

Now imagine a random sample falling in such a way that the minimum is below a fixed value x. It might
look like this

![image](https://user-images.githubusercontent.com/78324346/141743008-b1bec104-65dc-47a4-a3b3-49bde97a0601.png)

or this

![image](https://user-images.githubusercontent.com/78324346/141743037-a80cb12a-0ab8-4273-b87e-04002df9252e.png)

This means that 

![image](https://user-images.githubusercontent.com/78324346/141743116-14d38861-4fa2-4d96-a40e-08ba5f136b5f.png)

There are many ways for the individual Xi to fall so that the minimum is less than or equal to x. On the other hand, the minimum is greater than x if and only if all the Xi are greater than x.

So, it's easier to consider P(X(1) ≤ x) as the complementary of P(X(1) > x). Thus, we obtain the following result: 

![image](https://user-images.githubusercontent.com/78324346/141743372-6cde25e9-e86e-4bba-b24c-e71a9b32104f.png)

As it's possible to see in the previous image, because every random variable is identically distributed, it's considered only P(X1 > x) since P(X1 > x) = P(X2 > x) = ... = P(Xn > x).\
Also, since F(x) = P(X ≤ x) then P(X1 > x) is the complementary of the CDF and thus we write 1-F(x) instead.

Since the PDF is the derivative of the CDF, then, from the CDF of the minimum, we can compute the PDF as follows

![image](https://user-images.githubusercontent.com/78324346/141743894-f77b27eb-8da8-4345-8819-ea5f021a7239.png)

**The distribution of the maximum**\
Again consider our random sample X1, X2,..., Xn from a continuous distribution with PDF f and
CDF F. We will now derive the pdf for X(n), the maximum value of the sample. As with the minimum, we will consider the cdf and try to relate it to the behavior of the individual sampled values X1, X2,..., Xn. 

Imagine a random sample falling in such a way that the maximum is below a fixed value x. This
will happen if and only if all of the Xi are below x.

![image](https://user-images.githubusercontent.com/78324346/141745504-81d56d98-af9b-47ba-99fc-13e72bc957a2.png)

Then, we have that

![image](https://user-images.githubusercontent.com/78324346/141745546-511f1c2e-6570-4def-83f3-736c4599ea86.png)

As we did for the distribution of the minimum, also here we multiply n times P(X1 ≤ x) thanks to the random variables being identically distributed.

As before we can obtain the PDF as the derivative of the CDF

![image](https://user-images.githubusercontent.com/78324346/141745664-2ef994c5-10de-4926-9fee-4697c1da368b.png)

**The joint distribution of the minimum and maximum**\
To compute the PDF of the joint distribution, first, we need to find the formula for the CDF

![image](https://user-images.githubusercontent.com/78324346/141747682-8c863cfa-619b-49e9-8566-0ea955ba2d35.png)

To do so we can consider

![image](https://user-images.githubusercontent.com/78324346/141747822-3f94a386-4204-406e-9088-931a51dc5cad.png)
The first term on the right-hand side is what we want to compute.\
We have that P(X(1) > x, X(n) ≤ y) = 0 if x ≥ y. This is easy to understand, if x ≥ y since X(1) is the minimum value then X(n) > X(1) > x and so it's impossible to have X(n) ≤ y. \
So we consider the case where x < y.\
We have that

![image](https://user-images.githubusercontent.com/78324346/141748163-113da2b3-142c-401f-90e5-cf7578b2a555.png)

This is due to having the minimum order statistics that is greater than x and the maximum order statistics that is less than y. If the minimum is greater than x then all the other values will be. If the maximum is less than y then all the other values will be. \
We have that P(x < X1 ≤ y) = F(y) - F(x) because of the property of the integral. As before we can use only the probability related to X1 multiplied by itself n times thanks to the random variables being identically distributed.

So the CDF is

![image](https://user-images.githubusercontent.com/78324346/141748267-700a7c63-46c6-41f4-9d5d-42cd24b8468b.png)

where P(X(n) ≤ y) has been computed as explained before for the maximum order statistics.

And we can obtain the PDF as the derivative of the CDF

![image](https://user-images.githubusercontent.com/78324346/141748350-63aa309e-8a65-4135-989d-9258540b9dd8.png)

It's important to remember that this holds for x < y.

**The joint distribution for all of the order statistics**\
Now we want to find the following PDF

![image](https://user-images.githubusercontent.com/78324346/141749170-ffdf79a2-12e9-499b-982f-386d8298ef33.png)

To do so we start from the join CDF

![image](https://user-images.githubusercontent.com/78324346/141750461-55075625-ff6d-4f9a-b05e-359dbe6c02f5.png)

But, since it's a little hard to work with it, we consider something similar:

![image](https://user-images.githubusercontent.com/78324346/141750577-88727847-dd8e-4aa7-b41a-40b6d0d7fccb.png)

where y1 < x1 ≤ y2 < x2 ≤ y3 < x3 ≤ ... ≤ yn < xn.

This can happen if X(1) = X1, X(2) = X2, ... and so

![image](https://user-images.githubusercontent.com/78324346/141750867-7eb79db8-4b3b-4aeb-848f-16288b78a5b2.png)

or if X(1) = X5, X(2) = X3, ... and so

![image](https://user-images.githubusercontent.com/78324346/141750909-7987b299-e449-46b2-bfdf-fb592780f5c9.png)

or if...

So we are generating the permutation of the random variables inside the intervals, this means that there are n! possibilities. Each of it has the same probability to happen since the random variables are identically distributed. Also, because of the constraints on the xi and yi, these are disjoint events.\
So, we can add these n! probabilities together to get

![image](https://user-images.githubusercontent.com/78324346/141751070-3cd9a6cf-b979-449c-ba41-e4034e0b53fb.png)

And we have the following

![image](https://user-images.githubusercontent.com/78324346/141751163-4e43e7b2-8bbd-4e01-bcf6-f06ed25a90e5.png)

We have that P(y1 < X(1) ≤ x1, ..., yn < X(n) < xn) is the CDF and so it is equal to

![image](https://user-images.githubusercontent.com/78324346/141751265-0f5978d8-56c0-4971-94d5-f053e310f813.png)

So by replacing the results just shown to the first presented formula of P(y1 < X(1) ≤ x1, ..., yn < X(n) < xn) and taking the derivatives of both left and right side with respect to x1,x2,...,xn we obtain

![image](https://user-images.githubusercontent.com/78324346/141751559-9bb7ca09-8396-4b75-9ac1-0599aff5c398.png)

which holds for x1 < x2 < ... < xn since X(1) has to be the minimum, X(2) has to be the second smallest value and so on.\
The PDF is zero otherwise, it's so since, for example, it is not possible that X(2) > X(1). 

**The distribution of k-th order statistics**\
![image](https://user-images.githubusercontent.com/78324346/141767577-1fb17ca2-1bc6-4824-87ee-5d9c6b615425.png)


[1][https://en.wikipedia.org/wiki/Order_statistic](https://en.wikipedia.org/wiki/Order_statistic)\
[2][https://www.colorado.edu/amath/sites/default/files/attached-files/order_stats.pdf](https://www.colorado.edu/amath/sites/default/files/attached-files/order_stats.pdf)
